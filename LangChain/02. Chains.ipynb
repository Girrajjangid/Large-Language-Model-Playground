{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Chains\n",
    "chains in Langchain, elucidating their function and importance in the structure of the language model. We learn about the different types of chain and their use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import langchain as lc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n    sentiment: \"positive\",\\n    subject: \"Pizza\"\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "\n",
    "llm = lc.OpenAI(temperature=0)\n",
    "prompt_template = lc.PromptTemplate.from_template(template=template)\n",
    "chain = lc.LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.predict(input=\"I ordered Pizza Salami and it was awesome!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sequential Chains\n",
    "Sometimes we want to pass the output from one model to a another model. This can be done with different SequentialChains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template=\"\\nYou are a helpful bot that creates a 'thank you' reponse text. \\nIf customers are unsatisfied, offer them a real world assitant to talk to. \\nYou will get a sentiment and subject as into and evaluate. \\n\\ntext: {input}\\n\", template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_template = \"\"\"\n",
    "You are a helpful bot that creates a 'thank you' reponse text. \n",
    "If customers are unsatisfied, offer them a real world assitant to talk to. \n",
    "You will get a sentiment and subject as into and evaluate. \n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "review_template = lc.PromptTemplate(input_variables=['input'], template=response_template)\n",
    "review_chain = lc.LLMChain(llm=llm, prompt=review_template)\n",
    "review_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "{\n",
      "    sentiment: \"Negative\",\n",
      "    subject: \"Pizza\"\n",
      "}\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "I'm sorry to hear that you are unhappy with your pizza. We would like to make it right for you. Please reach out to our customer service team and they will be happy to assist you. Thank you for bringing this to our attention.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nI'm sorry to hear that you are unhappy with your pizza. We would like to make it right for you. Please reach out to our customer service team and they will be happy to assist you. Thank you for bringing this to our attention.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain = lc.chains.SimpleSequentialChain(chains=[chain, review_chain],\n",
    "                                                verbose=True)\n",
    "overall_chain.run(input=\"I ordered Pizza salami & was aweful!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Chains can be more complex and not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a more complex chain.\n",
    "\n",
    "# This is an LLMChain to write a review given a dish name and the experience.\n",
    "prompt_review = lc.PromptTemplate.from_template(\n",
    "    template=\"You ordered {dish_name} and your experience was {experience}. Write a review: \"\n",
    ")\n",
    "chain_review = lc.LLMChain(llm=llm, prompt=prompt_review, \n",
    "                           output_key=\"review\")\n",
    "\n",
    "# This is an LLMChain to write a follow-up comment given the restaurant review.\n",
    "prompt_comment = lc.PromptTemplate.from_template(\n",
    "    template=\"Given the restaurant review: {review}, write a follow-up comment: \"\n",
    ")\n",
    "chain_comment = lc.LLMChain(llm=llm, prompt=prompt_comment, \n",
    "                            output_key=\"comment\")\n",
    "\n",
    "# This is an LLMChain to summarize a review.\n",
    "prompt_summary = lc.PromptTemplate.from_template(\n",
    "    template=\"Summarise the review in one short sentence: \\n\\n {review}\"\n",
    ")\n",
    "chain_summary = lc.LLMChain(llm=llm, prompt=prompt_summary, \n",
    "                            output_key=\"summary\")\n",
    "\n",
    "# This is an LLMChain to translate a summary into Hindi.\n",
    "prompt_translation = lc.PromptTemplate.from_template(\n",
    "    template=\"Translate the summary to Hindi: \\n\\n {summary}\"\n",
    ")\n",
    "chain_translation = lc.LLMChain(llm=llm, prompt=prompt_translation, \n",
    "                                output_key=\"hindi_translation\"\n",
    ")\n",
    "\n",
    "overall_chain = lc.chains.SequentialChain(\n",
    "    chains=[chain_review, chain_comment, chain_summary, chain_translation],\n",
    "    input_variables=[\"dish_name\", \"experience\"],\n",
    "    output_variables=[\"review\", \"comment\", \"summary\", \"hindi_translation\"],\n",
    ")\n",
    "\n",
    "output = overall_chain({\"dish_name\": \"Pizza Salami\", \n",
    "               \"experience\": \"It was awful!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish_name : Pizza Salami\n",
      "experience : It was awful!\n",
      "review : \n",
      "\n",
      "I recently ordered a Pizza Salami from this restaurant and I was extremely disappointed. The pizza was dry and tasteless, and the salami was of poor quality. The crust was also too thick and hard. Overall, I would not recommend this pizza to anyone.\n",
      "comment : \n",
      "\n",
      "I'm sorry to hear that you didn't enjoy your pizza. We strive to provide the best quality food and service to our customers, so we apologize if we didn't meet your expectations. We would love to have another chance to make it up to you. Please let us know if there is anything we can do.\n",
      "summary : \n",
      "\n",
      "This restaurant's Pizza Salami was of poor quality and not worth recommending.\n",
      "hindi_translation : \n",
      "\n",
      "इस रेस्तरां का पिज़्ज़ा सलामी की गुणवत्ता बुरी थी और सिफारिश की जाने योग्य नहीं था।\n"
     ]
    }
   ],
   "source": [
    "def printOutput(d):\n",
    "    for k,v in d.items():\n",
    "        print(k,\":\",v)\n",
    "\n",
    "printOutput(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of chaining multiple chains together we can also use an LLM to decide which follow up chain is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_template = \"\"\"You are an AI bot that focuses on the positive side of things. \\\n",
    "Whenever you analyze a text, you look for the positive aspects and highlight them. \\\n",
    "Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_template = \"\"\"You are an AI bot that has a neutral perspective. You just provide a balanced analysis of the text, \\\n",
    "not favoring any positive or negative aspects. Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_template = \"\"\"You are an AI bot that is designed to find the negative aspects in a text. \\\n",
    "You analyze a text and show the potential downsides. Here is the text:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='You are an AI bot that focuses on the positive side of things. Whenever you analyze a text, you look for the positive aspects and highlight them. Here is the text:\\n{input}', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}),\n",
       " 'neutral': LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='You are an AI bot that has a neutral perspective. You just provide a balanced analysis of the text, not favoring any positive or negative aspects. Here is the text:\\n{input}', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}),\n",
       " 'negative': LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='You are an AI bot that is designed to find the negative aspects in a text. You analyze a text and show the potential downsides. Here is the text:\\n{input}', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={})}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive\",\n",
    "        \"description\": \"Good for analyzing positive sentiments\",\n",
    "        \"prompt_template\": positive_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neutral\",\n",
    "        \"description\": \"Good for analyzing neutral sentiments\",\n",
    "        \"prompt_template\": neutral_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative\",\n",
    "        \"description\": \"Good for analyzing negative sentiments\",\n",
    "        \"prompt_template\": negative_template,\n",
    "    },\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    prompt = lc.PromptTemplate(template=p_info[\"prompt_template\"], \n",
    "                            input_variables=[\"input\"])\n",
    "    chain = lc.LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[p_info[\"name\"]] = chain\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "positive: {'input': 'I ordered Pizza Salami for 9.99$ and it was amazing!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI'm glad to hear that you enjoyed your pizza! It sounds like you got a great deal for a delicious meal.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = lc.chains.router.multi_prompt_prompt.MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = lc.PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=lc.chains.router.llm_router.RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = lc.chains.router.llm_router.LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = lc.chains.router.MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=destination_chains[\"neutral\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.run(\"I ordered Pizza Salami for 9.99$ and it was awesome!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- END --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
