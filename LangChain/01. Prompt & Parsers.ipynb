{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "`LangChain` is a framework for developing applications powered by language models. It enables applications that are:\n",
    "\n",
    "`Data-aware:` connect a language model to other sources of data\n",
    "Agentic: allow a language model to interact with its environment\n",
    "The main value props of LangChain are:\n",
    "\n",
    "`Components:` abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not\n",
    "Off-the-shelf chains: a structured assembly of components for accomplishing specific higher-level tasks\n",
    "Off-the-shelf chains make it easy to get started. For more complex applications and nuanced use-cases, components make it easy to customize existing chains or build new ones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai\n",
    "!pip install langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file and write this line [your OPENAI key]\n",
    "# You will get OPENAI key from \n",
    "# platform.openai.com -> Personal -> view API keys -> create new one & copy paste in .env \n",
    "# OPENAI_API_KEY=\"sk-rkqECXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv()) # This will return True if successfully loaded OPENAI KEY\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If above code not loading your key then use this.\n",
    "def loadKey():\n",
    "    my_key = open('.env').read().split('=')[1][1:-1]\n",
    "    os.environ[\"OPENAI_API_KEY\"] = my_key\n",
    "    openai.api_key = my_key\n",
    "loadKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a simple Chat-Response function\n",
    "\n",
    "def chat(input):\n",
    "    messages = [{\"role\": \"user\", \"content\": input}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chat(\"What is the capital of India\")\n",
    "output.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Be very funny when answering questions\n",
      "Question: What is the capital of India\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oh, that's easy! The capital of India is... wait for it... drumroll please... New York City! Just kidding, it's actually New Delhi. But wouldn't it be funny if it was New York City? Imagine all the confused tourists!\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of India\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Be very funny when answering questions\n",
    "Question: {question}\n",
    "\"\"\".format(question=question)\n",
    "\n",
    "print(prompt)\n",
    "chat(prompt).choices[0].message['content']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Templates makes creating a prompt for different usecases easier than using f-string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain as lc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see we don't require to create message for OpenAI.ChatCompletion\n",
    "llms = lc.llms.OpenAI(model_name = 'gpt-3.5-turbo')\n",
    "\n",
    "# Both are correct.\n",
    "#llms('What is capital of India?')\n",
    "llms.predict('what is the capital of india?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a prompt similar kind we creat in chatGPT.\n",
    "# We are expecting output in JSON format with 2 keys.\n",
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"sentiment\": \"positive\",\\n    \"subject\": \"pizza\"\\n}'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = lc.prompts.ChatPromptTemplate.from_template(template = template)\n",
    "chain = lc.chains.LLMChain(llm=llms, prompt=prompt_template)\n",
    "chain.predict(input='I order pizza salami and it was awesome!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Parser, ResponseSchema, Templates, Chains & OutputParsers\n",
    "We can see, we get desired output. But in string format. Let's convert it into much better way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_schema = lc.output_parsers.ResponseSchema(\n",
    "    name=\"sentiment\",\n",
    "    description=\"Is the text positive, neutral or negative? Only provide these words\",\n",
    ")\n",
    "subject_schema = lc.output_parsers.ResponseSchema(\n",
    "    name=\"subject\", \n",
    "    description=\"What subject is the text about? Use exactly one word.\"\n",
    ")\n",
    "price_schema = lc.output_parsers.ResponseSchema(\n",
    "    name=\"price\",\n",
    "    description=\"How expensive was the product? Use None if no price was provided in the text\",\n",
    ")\n",
    "\n",
    "response_schemas = [sentiment_schema, subject_schema, price_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // Is the text positive, neutral or negative? Only provide these words\\n\\t\"subject\": string  // What subject is the text about? Use exactly one word.\\n\\t\"price\": string  // How expensive was the product? Use None if no price was provided in the text\\n}\\n```'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't require to typing every instruction into chat.\n",
    "# StructuredOutputParser will do for us.\n",
    "parser = lc.output_parsers.StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"positive\",\\n\\t\"subject\": \"pizza\",\\n\\t\"price\": \"9.99$\"\\n}\\n```', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have instruction read.\n",
    "# let use with previous template\n",
    "\n",
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Just return the JSON, do not add ANYTHING, NO INTERPRETATION!\n",
    "\n",
    "text: {input}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = lc.prompts.ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "# String formatting\n",
    "messages = prompt.format_messages(\n",
    "    input=\"I ordered Pizza Salami for 9.99$ and it was awesome!\",\n",
    "    format_instructions=format_instructions)\n",
    "\n",
    "chat = lc.chat_models.ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'positive', 'subject': 'pizza', 'price': '9.99$'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = parser.parse(response.content)\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see. By just providing text input. we get,\n",
    "# sentiment, subject, price, without specifying in chat\n",
    "# what kind of output we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------ END ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
